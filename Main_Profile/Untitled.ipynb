{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eae732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the NSFG data\n",
    "# To get the number of rows and columns in a DataFrame, you can read its shape attribute.\n",
    "#\n",
    "# To get the column names, you can read the columns attribute. The result is an Index, which is a Pandas data structure that is similar to a list. Let's begin exploring the NSFG data! It has been pre-loaded for you into a DataFrame called nsfg.\n",
    "\n",
    "# value_counts() to see what values appear in pounds and how many times each value appears. By default results are sorted with most freq value first so using sort_index() sorts them by value instead\n",
    "\n",
    "# describe() computes summary stats\n",
    "\n",
    "# replace takes a list of values we want to replace and the value we want to replace them with\n",
    "\n",
    "pounds = pounds.replace([98, 99], np.nan) # np.nan means we are getting the special value NaN from the NumPy library\n",
    "\n",
    "# Clean a variable\n",
    "# In the NSFG dataset, the variable 'nbrnaliv' records the number of babies born alive at the end of a pregnancy.\n",
    "#\n",
    "# If you use .value_counts() to view the responses, you'll see that the value 8 appears once, and if you consult the codebook, you'll see that this value indicates that the respondent refused to answer the question.\n",
    "#\n",
    "# Your job in this exercise is to replace this value with np.nan. Recall from the video how Allen replaced the values 98 and 99 in the ounces column using the .replace() method:\n",
    "#\n",
    "# ounces.replace([98, 99], np.nan, inplace=True)\n",
    "\n",
    "# In the 'nbrnaliv' column, replace the value 8, in place, with the special value NaN.\n",
    "# Confirm that the value 8 no longer appears in this column by printing the values and their frequencies.\n",
    "\n",
    "# Replace the value 8 with NaN\n",
    "nsfg['nbrnaliv'].replace([8], np.nan, inplace=True)\n",
    "\n",
    "# Print the values and their frequencies\n",
    "print(nsfg['nbrnaliv'].value_counts())\n",
    "\n",
    "# Compute a variable\n",
    "# For each pregnancy in the NSFG dataset, the variable 'agecon' encodes the respondent's age at conception, and 'agepreg' the respondent's age at the end of the pregnancy.\n",
    "#\n",
    "# Both variables are recorded as integers with two implicit decimal places, so the value 2575 means that the respondent's age was 25.75.\n",
    "\n",
    "# Select the columns and divide by 100\n",
    "agecon = nsfg['agecon'] / 100\n",
    "agepreg = nsfg['agepreg'] / 100\n",
    "\n",
    "# Compute the difference\n",
    "preg_length = agepreg - agecon\n",
    "\n",
    "# Compute summary statistics\n",
    "print(preg_length.describe())\n",
    "\n",
    "# Good job. A variable that's computed from other variables is sometimes called a 'recode'. It's now time to get back to the motivating question for this chapter: what is the average birth weight for babies in the U.S.? See you in the next video!\n",
    "\n",
    "# ~ operator is logical NOT or inverse, for instance: full_term_weight = birth_weight[~preterm]\n",
    "\n",
    "# Make a histogram\n",
    "# Histograms are one of the most useful tools in exploratory data analysis. They quickly give you an overview of the distribution of a variable, that is, what values the variable can have, and how many times each value appears.\n",
    "#\n",
    "# As we saw in a previous exercise, the NSFG dataset includes a variable 'agecon' that records age at conception for each pregnancy. Here, you're going to plot a histogram of this variable. You'll use the bins parameter that you saw in the video, and also a new parameter - histtype - which you can read more about here in the matplotlib documentation. Learning how to read documentation is an essential skill. If you want to learn more about matplotlib, you can check out DataCamp's Introduction to Matplotlib course.\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(agecon, bins=20, histtype = 'step')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Age at conception')\n",
    "plt.ylabel('Number of pregnancies')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n",
    "\n",
    "# Compute birth weight\n",
    "# Now let's pull together the steps in this chapter to compute the average birth weight for full-term babies.\n",
    "#\n",
    "# I've provided a function, resample_rows_weighted, that takes the NSFG data and resamples using the sampling weights in wgt2013_2015. The result is a DataFrame, sample, that is representative of the U.S. population.\n",
    "#\n",
    "# Then I extract birthwgt_lb1 and birthwgt_oz1, replacing special codes with NaN:\n",
    "#\n",
    "# # Resample the data\n",
    "# sample = resample_rows_weighted(nsfg, 'wgt2013_2015')\n",
    "#\n",
    "# # Clean the weight variables\n",
    "# pounds = sample['birthwgt_lb1'].replace([98, 99], np.nan)\n",
    "# ounces = sample['birthwgt_oz1'].replace([98, 99], np.nan)\n",
    "\n",
    "# Use pounds and ounces to compute total birth weight.\n",
    "# Make a Boolean Series called preterm that is true for babies with 'prglngth' less than 37 weeks.\n",
    "# Use preterm to select birth weight for babies that are not preterm. Store the result in full_term_weight.\n",
    "# Compute the mean weight of full term babies.\n",
    "\n",
    "# Compute total birth weight\n",
    "birth_weight = pounds + ounces/16\n",
    "\n",
    "# Create a Boolean Series for preterm babies\n",
    "preterm = sample['prglngth'] < 37\n",
    "\n",
    "# Select the weights of full term babies\n",
    "full_term_weight = birth_weight[~preterm]\n",
    "\n",
    "# Compute the mean weight of full term babies\n",
    "print(np.mean(full_term_weight))\n",
    "\n",
    "# Filter\n",
    "# In the previous exercise, you computed the mean birth weight for full-term babies; you filtered out preterm babies because their distribution of weight is different.\n",
    "#\n",
    "# The distribution of weight is also different for multiple births, like twins and triplets. In this exercise, you'll filter them out, too, and see what effect it has on the mean.\n",
    "\n",
    "# Use the variable 'nbrnaliv' to make a Boolean Series that is True for single births (where 'nbrnaliv' equals 1) and False otherwise.\n",
    "# Use Boolean Series and logical operators to select single, full-term babies and compute their mean birth weight.\n",
    "# For comparison, select multiple, full-term babies and compute their mean birth weight.\n",
    "\n",
    "# Filter preterm babies\n",
    "preterm = sample['prglngth'] < 37\n",
    "\n",
    "# Filter single births\n",
    "single = sample['nbrnaliv'] == 1\n",
    "\n",
    "# Compute birth weight for single full-term babies\n",
    "single_full_term_weight = birth_weight[~preterm & single]\n",
    "print('Single full-term mean:', single_full_term_weight.mean())\n",
    "\n",
    "# Compute birth weight for multiple full-term babies\n",
    "mult_full_term_weight = birth_weight[~preterm & ~single]\n",
    "print('Multiple full-term mean:', mult_full_term_weight.mean())\n",
    "\n",
    "plt.hist(educ.dropna(), label='educ')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# PMF or probabilty Mass Function that contains the unique values in the dataset and how often each one appears\n",
    "\n",
    "# Make a PMF\n",
    "# The GSS dataset has been pre-loaded for you into a DataFrame called gss. You can explore it in the IPython Shell to get familiar with it.\n",
    "#\n",
    "# In this exercise, you'll focus on one variable in this dataset, 'year', which represents the year each respondent was interviewed.\n",
    "\n",
    "# Plot a PMF\n",
    "# Now let's plot a PMF for the age of the respondents in the GSS dataset. The variable 'age' contains respondents' age in years.\n",
    "\n",
    "# Select the age column\n",
    "age = gss['age']\n",
    "\n",
    "# Make a PMF of age\n",
    "pmf_age = Pmf(age)\n",
    "\n",
    "# Plot the PMF\n",
    "pmf_age.bar()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('PMF')\n",
    "plt.show()\n",
    "\n",
    "# PMF represents the possible values in a distribution and their probabilities\n",
    "# CDF or Cumulative Distribution Functions; great way to visualise and compare distributions\n",
    "\n",
    "# From PMF to CDF\n",
    "# If you draw a random element from a distribution:\n",
    "\n",
    "# - PMF (Probability Mass Function) is the probability that you get exactly x\n",
    "# - CDF (Cumulative Distribution Function) is the probability you get a value   <= x for a given value of x\n",
    "\n",
    "# CDF is an invertible function which means that if u have a prob p you can look up the corresponding quantity q\n",
    "\n",
    "# The distance from the 25th to the 75th percentile is called the IQR. It measures the spread of the distribution so it is similar to sd or variance\n",
    "\n",
    "# IQR can be more robust than variance\n",
    "\n",
    "# Compute IQR\n",
    "# Recall from the video that the interquartile range (IQR) is the difference between the 75th and 25th percentiles. It is a measure of variability that is robust in the presence of errors or extreme values.\n",
    "#\n",
    "# In this exercise, you'll compute the interquartile range of income in the GSS dataset. Income is stored in the 'realinc' column, and the CDF of income has already been computed and stored in cdf_income.\n",
    "\n",
    "# Calculate the 75th percentile\n",
    "percentile_75th = cdf_income.inverse(0.75)\n",
    "\n",
    "# Calculate the 25th percentile\n",
    "percentile_25th = cdf_income.inverse(0.25)\n",
    "\n",
    "# Calculate the interquartile range\n",
    "iqr = percentile_75th - percentile_25th\n",
    "\n",
    "# Print the interquartile range\n",
    "print(iqr)\n",
    "\n",
    "# Plot a CDF\n",
    "# The distribution of income in almost every country is long-tailed; that is, there are a small number of people with very high incomes.\n",
    "#\n",
    "# In the GSS dataset, the variable 'realinc' represents total household income, converted to 1986 dollars. We can get a sense of the shape of this distribution by plotting the CDF.\n",
    "\n",
    "# Select realinc\n",
    "income = gss['realinc']\n",
    "\n",
    "# Make the CDF\n",
    "cdf_income = Cdf(income)\n",
    "\n",
    "# Plot it\n",
    "cdf_income.plot()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Income (1986 USD)')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()\n",
    "\n",
    "# Comparing distributionsm, in general CDFs are smoother thatn PMFs\n",
    "\n",
    "# Extract education levels\n",
    "# Let's create Boolean Series to identify respondents with different levels of education.\n",
    "#\n",
    "# In the U.S, 12 years of education usually means the respondent has completed high school (secondary education). A respondent with 14 years of education has probably completed an associate degree (two years of college); someone with 16 years has probably completed a bachelor's degree (four years of college).\n",
    "\n",
    "# Complete the line that identifies respondents with associate degrees, that is, people with more than 14 years of education but less than 16.\n",
    "# Complete the line that identifies respondents with 12 or fewer years of education.\n",
    "# Confirm that the mean of high is the fraction we computed in the previous exercise, about 53%.\n",
    "\n",
    "# Plot income CDFs\n",
    "# Let's now see what the distribution of income looks like for people with different education levels. You can do this by plotting the CDFs. Recall how Allen plotted the income CDFs of respondents interviewed before and after 1995:\n",
    "#\n",
    "# Cdf(income[pre95]).plot(label='Before 1995')\n",
    "# Cdf(income[~pre95]).plot(label='After 1995')\n",
    "# You can assume that Boolean Series have been defined, as in the previous exercise, to identify respondents with different education levels: high, assc, bach, and post.\n",
    "\n",
    "income = gss['realinc']\n",
    "\n",
    "# Plot the CDFs\n",
    "Cdf(income[high]).plot(label='High school')\n",
    "Cdf(income[assc]).plot(label='Associate')\n",
    "Cdf(income[bach]).plot(label='Bachelor')\n",
    "Cdf(income[post]).plot(label='Postgraduate')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Income (1986 USD)')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Estimate PDFs from data\n",
    "# SciPy provides an object called norm that represents the normal distribution\n",
    "\n",
    "\n",
    "sample = np.random.normal(size=1000)\n",
    "\n",
    "sample\n",
    "\n",
    "# Create an array of equally spaced points from -3 to 3\n",
    "import numpy as np\n",
    "xs = np.linspace(-3, 3)\n",
    "\n",
    "# norm(0,1) creates an obj that represents a normal distribution with mean 0 and sd 1. .cdf evaluates the cdf of the normal dist\n",
    "ys = norm(0,1).cdf(xs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(xs, ys, color = 'gray')\n",
    "\n",
    "# Plotting the cdf of the normal distributon and actual data\n",
    "\n",
    "ys = norm(0,1).pdf(xs) # evaluates the PDF (probability density function)\n",
    "\n",
    "plt.plot(xs, ys, color = 'gray')\n",
    "\n",
    "# Kernel Density Estimation: A way of getting from a PMF to a PDF\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# kdeplot from seaborn takes the sample, estimates the pdf and then plots it\n",
    "sns.kdeplot(sample)\n",
    "\n",
    "# compare the KDE plot with the normal PDF\n",
    "\n",
    "# 3 ways to visualise distributions:\n",
    "# CDFs: for exploration\n",
    "# PMFs if there are a small number of unique values\n",
    "# KDE if there are a lot of values\n",
    "\n",
    "# Distribution of income\n",
    "# In many datasets, the distribution of income is approximately lognormal, which means that the logarithms of the incomes fit a normal distribution. We'll see whether that's true for the GSS data. As a first step, you'll compute the mean and standard deviation of the log of incomes using NumPy's np.log10() function.\n",
    "#\n",
    "# Then, you'll use the computed mean and standard deviation to make a norm object using the scipy.stats.norm() function.\n",
    "\n",
    "# Extract 'realinc' from gss and compute its logarithm using np.log10().\n",
    "# Compute the mean and standard deviation of the result.\n",
    "# Make a norm object by passing the computed mean and standard deviation to norm().\n",
    "\n",
    "# Extract realinc and compute its log\n",
    "income = gss['realinc']\n",
    "log_income = np.log10(income)\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "mean = log_income.mean()\n",
    "std = log_income.std()\n",
    "print(mean, std)\n",
    "\n",
    "# Make a norm object\n",
    "from scipy.stats import norm\n",
    "dist = norm(mean, std)\n",
    "\n",
    "# Comparing CDFs\n",
    "# To see whether the distribution of income is well modeled by a lognormal distribution, we'll compare the CDF of the logarithm of the data to the CDF of a normal distribution with the same mean and standard deviation. The dist object you created in the previous exercise is available for use:\n",
    "#\n",
    "# from scipy.stats import norm\n",
    "# dist = norm(mean, std)\n",
    "# This is a norm object with the same mean and standard deviation as the data. All scipy.stats.norm objects have a .cdf() method.\n",
    "\n",
    "# Evaluate the normal CDF using dist and xs.\n",
    "# Plot the CDF of the logarithms of the incomes, using log_income, which is a Series object.\n",
    "\n",
    "# Evaluate the normal CDF\n",
    "xs = np.linspace(2, 5.5)\n",
    "ys = dist.cdf(xs)\n",
    "\n",
    "# Plot the model CDF\n",
    "plt.clf()\n",
    "plt.plot(xs, ys, color='gray')\n",
    "\n",
    "# Plot the data CDF\n",
    "Cdf(log_income).plot()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('log10 of realinc')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()\n",
    "\n",
    "# Comparing PDFs\n",
    "# In the previous exercise, we used CDFs to see if the distribution of income is lognormal. We can make the same comparison using a PDF and KDE. That's what you'll do in this exercise!\n",
    "#\n",
    "# As before, the norm object dist is available in your workspace:\n",
    "#\n",
    "# from scipy.stats import norm\n",
    "# dist = norm(mean, std)\n",
    "# Just as all norm objects have a .cdf() method, they also have a .pdf() method.\n",
    "#\n",
    "# To create a KDE plot, you can use Seaborn's kdeplot() function. To learn more about this function and Seaborn, you can check out DataCamp's Data Visualization with Seaborn course. Here, Seaborn has been imported for you as sns.\n",
    "\n",
    "# Evaluate the normal PDF using dist, which is a norm object with the same mean and standard deviation as the data.\n",
    "# Make a KDE plot of the logarithms of the incomes, using log_income, which is a Series object.\n",
    "\n",
    "# Evaluate the normal PDF\n",
    "xs = np.linspace(2, 5.5)\n",
    "ys = dist.pdf(xs)\n",
    "\n",
    "# Plot the model PDF\n",
    "plt.clf()\n",
    "plt.plot(xs, ys, color='gray')\n",
    "\n",
    "# Plot the data KDE\n",
    "sns.kdeplot(log_income)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('log10 of realinc')\n",
    "plt.ylabel('PDF')\n",
    "plt.show()\n",
    "\n",
    "# Exploring relationships\n",
    "# jittering: adding random noise to data\n",
    "\n",
    "# PMF of age\n",
    "# Do people tend to gain weight as they get older? We can answer this question by visualizing the relationship between weight and age. But before we make a scatter plot, it is a good idea to visualize distributions one variable at a time. Here, you'll visualize age using a bar chart first. Recall that all PMF objects have a .bar() method to make a bar chart.\n",
    "#\n",
    "# The BRFSS dataset includes a variable, 'AGE' (note the capitalization!), which represents each respondent's age. To protect respondents' privacy, ages are rounded off into 5-year bins. 'AGE' contains the midpoint of the bins.\n",
    "\n",
    "# Extract the variable 'AGE' from the DataFrame brfss and assign it to age.\n",
    "# Plot the PMF of age as a bar chart.\n",
    "\n",
    "# Extract age\n",
    "age = brfss['AGE']\n",
    "\n",
    "# Plot the PMF\n",
    "Pmf(age).bar()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Age in years')\n",
    "plt.ylabel('PMF')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "# Now let's make a scatterplot of weight versus age. To make the code run faster, I've selected only the first 1000 rows from the brfss DataFrame.\n",
    "#\n",
    "# weight and age have already been extracted for you. Your job is to use plt.plot() to make a scatter plot.\n",
    "#\n",
    "\n",
    "# Make a scatter plot of weight and age with format string 'o' and alpha=0.1.\n",
    "\n",
    "# Select the first 1000 respondents\n",
    "brfss = brfss[:1000]\n",
    "\n",
    "# Extract age and weight\n",
    "age = brfss['AGE']\n",
    "weight = brfss['WTKG3']\n",
    "\n",
    "# Make a scatter plot\n",
    "plt.plot(age, weight, 'o', alpha=0.1)\n",
    "\n",
    "plt.xlabel('Age in years')\n",
    "plt.ylabel('Weight in kg')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# So far so good. By adjusting alpha we can avoid saturating the plot. Next we'll jitter the data to break up the columns.\n",
    "\n",
    "# Jittering\n",
    "# In the previous exercise, the ages fall in columns because they've been rounded into 5-year bins. If we jitter them, the scatter plot will show the relationship more clearly. Recall how Allen jittered height and weight in the video:\n",
    "#\n",
    "# height_jitter = height + np.random.normal(0, 2, size=len(brfss))\n",
    "# weight_jitter = weight + np.random.normal(0, 2, size=len(brfss))\n",
    "\n",
    "# Add random noise to age with mean 0 and standard deviation 2.5.\n",
    "# Make a scatter plot between weight and age with marker size 5 and alpha=0.2. Be sure to also specify 'o'.\n",
    "\n",
    "# Select the first 1000 respondents\n",
    "brfss = brfss[:1000]\n",
    "\n",
    "# Add jittering to age\n",
    "age = brfss['AGE'] + np.random.normal(0, 2.5, size=len(brfss))\n",
    "# Extract weight\n",
    "weight = brfss['WTKG3']\n",
    "\n",
    "# Make a scatter plot\n",
    "plt.plot(age, weight,  'o', markersize = 5, alpha = 0.2)\n",
    "\n",
    "plt.xlabel('Age in years')\n",
    "plt.ylabel('Weight in kg')\n",
    "plt.show()\n",
    "\n",
    "# Seaborn provides a function that makes violin plots but before using it we have to get rid of any rows with missing data\n",
    "# data = df.dropna(subset = ['AGE', 'WTKG3'])\n",
    "sns.violinplot(x = 'AGE', y = 'WTKG3', data = data, inner = None) # inner None simplifies the plot a little bit\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'AGE', y= 'WTKG3', data=data, whis=10) #whis = 10 to turn off a feature we don't need\n",
    "# Each box represent the IQR from the 25th to the 75th percentile\n",
    "\n",
    "# Height and weight\n",
    "# Previously we looked at a scatter plot of height and weight, and saw that taller people tend to be heavier. Now let's take a closer look using a box plot. The brfss DataFrame contains a variable '_HTMG10' that represents height in centimeters, binned into 10 cm groups.\n",
    "#\n",
    "# Recall how Allen created the box plot of 'AGE' and 'WTKG3' in the video, with the y-axis on a logarithmic scale:\n",
    "#\n",
    "# sns.boxplot(x='AGE', y='WTKG3', data=data, whis=10)\n",
    "# plt.yscale('log')\n",
    "\n",
    "# Fill in the parameters of .boxplot() to plot the distribution of weight ('WTKG3') in each height ('_HTMG10') group. Specify whis=10, just as was done in the video.\n",
    "# Add a line to plot the y-axis on a logarithmic scale.\n",
    "\n",
    "# Drop rows with missing data\n",
    "data = brfss.dropna(subset=['_HTMG10', 'WTKG3'])\n",
    "\n",
    "# Make a box plot\n",
    "sns.boxplot(x = '_HTMG10', y = 'WTKG3', data = data, whis=10)\n",
    "\n",
    "# Plot the y-axis on a log scale\n",
    "plt.yscale('log')\n",
    "\n",
    "# Remove unneded lines and label axes\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Height in cm')\n",
    "plt.ylabel('Weight in kg')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of income\n",
    "# In the next two exercises we'll look at relationships between income and other variables. In the BRFSS, income is represented as a categorical variable; that is, respondents are assigned to one of 8 income categories. The variable name is 'INCOME2'. Before we connect income with anything else, let's look at the distribution by computing the PMF. Recall that all Pmf objects have a .bar() method.\n",
    "\n",
    "# Extract 'INCOME2' from the brfss DataFrame and assign it to income.\n",
    "# Plot the PMF of income as a bar chart.\n",
    "\n",
    "# Extract income\n",
    "income = brfss['INCOME2']\n",
    "\n",
    "# Plot the PMF\n",
    "Pmf(income).bar()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Income level')\n",
    "plt.ylabel('PMF')\n",
    "plt.show()\n",
    "\n",
    "# Good work. Almost half of the respondents are in the top income category, so this dataset doesn't distinguish between the highest incomes and the median. But maybe it can tell us something about people with incomes below the median.\n",
    "\n",
    "# Income and height\n",
    "# Let's now use a violin plot to visualize the relationship between income and height.\n",
    "\n",
    "# Create a violin plot to plot the distribution of height ('HTM4') in each income ('INCOME2') group. Specify inner=None to simplify the plot.\n",
    "\n",
    "# Drop rows with missing data\n",
    "data = brfss.dropna(subset=['INCOME2', 'HTM4'])\n",
    "\n",
    "# Make a violin plot\n",
    "sns.violinplot(x = 'INCOME2', y = 'HTM4', data = data, inner = None)\n",
    "\n",
    "# Remove unneded lines and label axes\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('Income level')\n",
    "plt.ylabel('Height in cm')\n",
    "plt.show()\n",
    "\n",
    "# If correlation is high, that is close to 1 or -1 you can conclude that there is a strong linear relationship\n",
    "\n",
    "# But if the correlation is close to 0 that does not mean there is no relationship; there might be a strong non-linear relationship!\n",
    "\n",
    "# Computing correlations\n",
    "# The purpose of the BRFSS is to explore health risk factors, so it includes questions about diet. The variable '_VEGESU1' represents the number of servings of vegetables respondents reported eating per day.\n",
    "#\n",
    "# Let's see how this variable relates to age and income.\n",
    "\n",
    "# From the brfss DataFrame, select the columns 'AGE', 'INCOME2', and '_VEGESU1'.\n",
    "# Compute the correlation matrix for these variables.\n",
    "\n",
    "# Select columns\n",
    "columns = ['AGE', 'INCOME2', '_VEGESU1']\n",
    "subset = brfss[columns]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "print(subset.corr())\n",
    "\n",
    "# Income and vegetables\n",
    "# As we saw in a previous exercise, the variable '_VEGESU1' represents the number of vegetable servings respondents reported eating per day.\n",
    "#\n",
    "# Let's estimate the slope of the relationship between vegetable consumption and income.\n",
    "\n",
    "# Extract the columns 'INCOME2' and '_VEGESU1' from subset into xs and ys respectively.\n",
    "# Compute the simple linear regression of these variables.\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Extract the variables\n",
    "subset = brfss.dropna(subset=['INCOME2', '_VEGESU1'])\n",
    "xs = subset['INCOME2']\n",
    "ys = subset['_VEGESU1']\n",
    "\n",
    "# Compute the linear regression\n",
    "res = linregress(xs, ys)\n",
    "print(res)\n",
    "\n",
    "# Fit a line\n",
    "# Continuing from the previous exercise:\n",
    "#\n",
    "# Assume that xs and ys contain income codes and daily vegetable consumption, respectively, and\n",
    "#\n",
    "# res contains the results of a simple linear regression of ys onto xs.\n",
    "#\n",
    "# Now, you're going to compute the line of best fit. NumPy has been imported for you as np.\n",
    "\n",
    "# Set fx to the minimum and maximum of xs, stored in a NumPy array.\n",
    "# Set fy to the points on the fitted line that correspond to the xs.\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.clf()\n",
    "x_jitter = xs + np.random.normal(0, 0.15, len(xs))\n",
    "plt.plot(x_jitter, ys, 'o', alpha=0.2)\n",
    "\n",
    "# Plot the line of best fit\n",
    "fx = np.array([xs.min(), xs.max()])\n",
    "fy = res.intercept + res.slope * fx\n",
    "plt.plot(fx, fy, '-', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Income code')\n",
    "plt.ylabel('Vegetable servings per day')\n",
    "plt.ylim([0, 6])\n",
    "plt.show()\n",
    "\n",
    "# Using StatsModels\n",
    "# Let's run the same regression using SciPy and StatsModels, and confirm we get the same results.\n",
    "\n",
    "# Compute the regression between 'INCOME2' and '_VEGESU1' using SciPy's linregress().\n",
    "# Compute the regression between 'INCOME2' and '_VEGESU1' using StatsModels, with '_VEGESU1' as the intercept.\n",
    "\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Run regression with linregress\n",
    "subset = brfss.dropna(subset=['INCOME2', '_VEGESU1'])\n",
    "xs = subset['INCOME2']\n",
    "ys = subset['_VEGESU1']\n",
    "res = linregress(xs, ys)\n",
    "print(res)\n",
    "\n",
    "# Run regression with StatsModels\n",
    "results = smf.ols('_VEGESU1 ~ INCOME2', data = brfss).fit()\n",
    "print(results.params)\n",
    "\n",
    "# Correlation and simple regression can't measure non-linear relationships but multiple regression can\n",
    "\n",
    "# Plot income and edcuation\n",
    "# To get a closer look at the relationship between income and education, let's use the variable 'educ' to group the data, then plot mean income in each group.\n",
    "#\n",
    "# Here, the GSS dataset has been pre-loaded into a DataFrame called gss.\n",
    "\n",
    "# Group gss by 'educ'. Store the result in grouped.\n",
    "# From grouped, extract 'realinc' and compute the mean.\n",
    "# Plot mean_income_by_educ as a scatter plot. Specify 'o' and alpha=0.5.\n",
    "\n",
    "# Group by educ\n",
    "grouped = gss.groupby('educ')\n",
    "\n",
    "# Compute mean income in each group\n",
    "mean_income_by_educ = grouped['realinc'].mean()\n",
    "\n",
    "# Plot mean income as a scatter plot\n",
    "plt.plot(mean_income_by_educ, 'o', alpha = 0.5)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Education (years)')\n",
    "plt.ylabel('Income (1986 $)')\n",
    "plt.show()\n",
    "\n",
    "# Well done. It looks like the relationship between income and education is non-linear.\n",
    "\n",
    "# Non-linear model of education\n",
    "# The graph in the previous exercise suggests that the relationship between income and education is non-linear. So let's try fitting a non-linear model.\n",
    "\n",
    "# Add a column named 'educ2' to the gss DataFrame; it should contain the values from 'educ' squared.\n",
    "# Run a regression model that uses 'educ', 'educ2', 'age', and 'age2' to predict 'realinc'.\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Add a new column with educ squared\n",
    "gss['educ2'] = gss['educ'] ** 2\n",
    "\n",
    "# Run a regression model with educ, educ2, age, and age2\n",
    "results = smf.ols('realinc ~ educ + educ2 + age + age2', data = gss).fit()\n",
    "\n",
    "# Print the estimated parameters\n",
    "print(results.params)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['age'] = np.linspace(18, 85)\n",
    "df['age2'] = df['age'] ** 2\n",
    "df['educ'] = 12\n",
    "df['educ2'] = df['educ'] ** 2\n",
    "\n",
    "# Making predictions\n",
    "# At this point, we have a model that predicts income using age, education, and sex.\n",
    "#\n",
    "# Let's see what it predicts for different levels of education, holding age constant.\n",
    "\n",
    "# Using np.linspace(), add a variable named 'educ' to df with a range of values from 0 to 20.\n",
    "# Add a variable named 'age' with the constant value 30.\n",
    "# Use df to generate predicted income as a function of education.\n",
    "\n",
    "# Run a regression model with educ, educ2, age, and age2\n",
    "results = smf.ols('realinc ~ educ + educ2 + age + age2', data=gss).fit()\n",
    "\n",
    "# Make the DataFrame\n",
    "df = pd.DataFrame()\n",
    "df['educ'] = np.linspace(0, 20)\n",
    "df['age'] = 30\n",
    "df['educ2'] = df['educ']**2\n",
    "df['age2'] = df['age']**2\n",
    "\n",
    "# Generate and plot the predictions\n",
    "pred = results.predict(df)\n",
    "print(pred.head())\n",
    "\n",
    "# Visualizing predictions\n",
    "# Now let's visualize the results from the previous exercise!\n",
    "\n",
    "# Plot mean_income_by_educ using circles ('o'). Specify an alpha of 0.5.\n",
    "# Plot the prediction results with a line, with df['educ'] on the x-axis and pred on the y-axis.\n",
    "\n",
    "# Plot mean income in each age group\n",
    "plt.clf()\n",
    "grouped = gss.groupby('educ')\n",
    "mean_income_by_educ = grouped['realinc'].mean()\n",
    "plt.plot(mean_income_by_educ, 'o', alpha = 0.5)\n",
    "\n",
    "# Plot the predictions\n",
    "pred = results.predict(df)\n",
    "plt.plot(df['educ'], pred, label='Age 30')\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('Education (years)')\n",
    "plt.ylabel('Income (1986 $)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Logistic regression: categorical variables\n",
    "\n",
    "# Parameters of a logistic regression are in the form of log odds\n",
    "\n",
    "# Positive values are associated with things that make the outcome more likely; (-) values make the outcome less likely\n",
    "\n",
    "# Log regression is a powerful tool for exploring relationships between a binary variable and the factors that predict it\n",
    "\n",
    "# Predicting a binary variable\n",
    "# Let's use logistic regression to predict a binary variable. Specifically, we'll use age, sex, and education level to predict support for legalizing cannabis (marijuana) in the U.S.\n",
    "#\n",
    "# In the GSS dataset, the variable grass records the answer to the question \"Do you think the use of marijuana should be made legal or not?\"\n",
    "\n",
    "# Recode grass\n",
    "gss['grass'].replace(2, 0, inplace=True)\n",
    "\n",
    "# Run logistic regression\n",
    "results = smf.logit('grass ~ age + age2 + educ + educ2 + C(sex)', data=gss).fit()\n",
    "results.params\n",
    "\n",
    "# Make a DataFrame with a range of ages\n",
    "df = pd.DataFrame()\n",
    "df['age'] = np.linspace(18, 89)\n",
    "df['age2'] = df['age']**2\n",
    "\n",
    "# Set the education level to 12\n",
    "df['educ'] = 12\n",
    "df['educ2'] = df['educ']**2\n",
    "\n",
    "# Generate predictions for men and women\n",
    "df['sex'] = 1\n",
    "pred1 = results.predict(df)\n",
    "\n",
    "df['sex'] = 2\n",
    "pred2 = results.predict(df)\n",
    "\n",
    "plt.clf()\n",
    "grouped = gss.groupby('age')\n",
    "favor_by_age = grouped['grass'].mean()\n",
    "plt.plot(favor_by_age, 'o', alpha=0.5)\n",
    "\n",
    "plt.plot(df['age'], pred1, label='Male')\n",
    "plt.plot(df['age'], pred2, label = 'Female')\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Probability of favoring legalization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
